{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1: Kaggle competitions process\n",
    "\n",
    "In this first chapter, you will get exposure to the Kaggle competition process. You will train a model and prepare a csv file ready for submission. You will learn the difference between Public and Private test splits, and how to prevent overfitting.\n",
    "\n",
    "\n",
    "- 1.1 Competitions overview\n",
    "    - Explore train data\n",
    "    - Explore test data  \n",
    "    <br />\n",
    "- 1.2 Prepare your first submission\n",
    "    - Determine a problem type\n",
    "    - Train a simple model\n",
    "    - Prepare a submission  \n",
    "    <br />    \n",
    "- 1.3 Public vs Private leaderboard\n",
    "    - What model is overfitting?\n",
    "    - Train XGBoost models\n",
    "    - Explore overfitting XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Overview\n",
    "- Explore train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'fare_amount',\n",
       " 'pickup_datetime',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'passenger_count']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read train data\n",
    "taxi_train = pd.read_csv('datasets/taxi_train_chapter_4.csv')\n",
    "taxi_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'pickup_datetime',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'passenger_count']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 'fare_amount' column is missing in test data because this is the column that we are predicting.\"\"\"\n",
    "\n",
    "# Read test data\n",
    "taxi_test = pd.read_csv('datasets/taxi_test_chapter_4.csv')\n",
    "taxi_test.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key  fare_amount\n",
       "0  2015-01-27 13:08:24.0000002        11.35\n",
       "1  2015-01-27 13:08:24.0000003        11.35\n",
       "2  2011-10-08 11:53:44.0000002        11.35\n",
       "3  2012-12-01 21:12:12.0000002        11.35\n",
       "4  2012-12-01 21:12:12.0000003        11.35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the sample submission file\n",
    "taxi_sample_sub = pd.read_csv('datasets/taxi_sample_submission.csv')\n",
    "taxi_sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 782526 to 499585\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   date    30000 non-null  object\n",
      " 1   store   30000 non-null  int64 \n",
      " 2   item    30000 non-null  int64 \n",
      " 3   sales   30000 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguyenngochai\\.conda\\envs\\my_conda_env\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "# load forcasting train data\n",
    "df_full = pd.read_csv('datasets/train.csv')\n",
    "# test = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "# Randomly use 30000 of your dataframe\n",
    "df = df_full.sample(n=30000, random_state=1)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "# dtest = xgb.DMatrix(data=test[['store', 'item']])\n",
    "\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {  'objective': 'reg:linear',\n",
    "            'max_depth': 2,\n",
    "            # 'max_depth': 8,\n",
    "            # 'max_depth': 15,\n",
    "            'verbosity': 0}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_2 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {  'objective': 'reg:linear',\n",
    "            #'max_depth': 2,\n",
    "            'max_depth': 8,\n",
    "            # 'max_depth': 15,\n",
    "            'verbosity': 0}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_8 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {  'objective': 'reg:linear',\n",
    "            #'max_depth': 2,\n",
    "            # 'max_depth': 8,\n",
    "            'max_depth': 15,\n",
    "            'verbosity': 0}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_15 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {  'objective': 'reg:linear',\n",
    "            #'max_depth': 2,\n",
    "            # 'max_depth': 8,\n",
    "            'max_depth': 30,\n",
    "            'verbosity': 0}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_30 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore overfitting XGBoost\n",
    "Having trained 3 XGBoost models with different maximum depths, you will now evaluate their quality. For this purpose, you will measure the quality of each model on both the train data and the test data. As you know by now, the train data is the data models have been trained on. The test data is the next month sales data that models have never seen before.\n",
    "\n",
    "The goal of this exercise is to determine whether any of the models trained is overfitting. To measure the quality of the models you will use Mean Squared Error (MSE). It's available in sklearn.metrics as mean_squared_error() function that takes two arguments: true values and predicted values.\n",
    "\n",
    "train and test DataFrames together with 3 models trained (xg_depth_2, xg_depth_8, xg_depth_15) are available in your workspace.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    -  Make predictions for each model on both the train and test data.\n",
    "    -  Calculate the MSE between the true values and your predictions for both the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 15000\n",
      "MSE Train: 600.630. MSE Test: 601.486\n",
      "MSE Train: 295.394. MSE Test: 301.276\n",
      "MSE Train: 252.848. MSE Test: 263.355\n",
      "MSE Train: 251.809. MSE Test: 262.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguyenngochai\\.conda\\envs\\my_conda_env\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "c:\\Users\\nguyenngochai\\.conda\\envs\\my_conda_env\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "dtrain_ = xgb.DMatrix(data=train[['store', 'item']])\n",
    "dtest = xgb.DMatrix(data=test[['store', 'item']])\n",
    "print(len(train), len(test))\n",
    "\n",
    "# For each of 3 trained models\n",
    "for model in [xg_depth_2, xg_depth_8, xg_depth_15,xg_depth_30]:\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(dtrain_)     \n",
    "    test_pred = model.predict(dtest)          \n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse_train = mean_squared_error(train['sales'], train_pred)                  \n",
    "    mse_test = mean_squared_error(test['sales'], test_pred)\n",
    "    print('MSE Train: {:.3f}. MSE Test: {:.3f}'.format(mse_train, mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f080ef3f7e154a5496448b61eb994fbc79c03fae547c033702ffc1b7b2a346b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('my_conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
